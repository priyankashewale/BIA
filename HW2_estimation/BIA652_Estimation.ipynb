{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BIA652_Estimation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7  ('base': conda)"},"language_info":{"name":"python","version":"3.7.1","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"dc99e0612049eb9171e9aad7f8dc04962fa7dfa02942ff09fb19aa684a3e1395"}},"cells":[{"cell_type":"code","metadata":{"id":"Qqb7gbNuDhOT"},"source":["# import packages\n","import numpy as np\n","\n","from scipy.optimize import minimize\n","from scipy.optimize import fsolve\n","import scipy.stats as stats\n","\n","import statsmodels.api as sm\n","import matplotlib.pyplot as plt\n","from functools import partial\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zyu3oZV_Tp9F"},"source":["# Maximum likelihood estimation (MLE)"]},{"cell_type":"markdown","metadata":{"id":"NrCl61bzXRcs"},"source":["## Example 1: Normal distribution"]},{"cell_type":"code","metadata":{"id":"kisic5EBt3ja"},"source":["raw_data1 = np.loadtxt('https://fmai-teaching.s3.amazonaws.com/bia652/est/n.txt')\n","histogram = plt.hist(raw_data1, bins=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1eUGQYh4Kzuz"},"source":["raw_data1[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HTRLcB8eKzuz"},"source":["# the likelihood of first data point when mu = 0, sigma = 1\n","stats.norm.pdf(raw_data1[0], loc=0, scale=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bgUlDZrGKzu0"},"source":["# the likelihood of first data point when mu = 10, sigma = 10\n","stats.norm.pdf(raw_data1[0], loc=10, scale=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wXC8F6uhTvC4"},"source":["# suppose we posit that the data is generated by a normal distribution\n","# now we find the parameters in normal distribution that most likely generated the data\n","\n","# now let's define a function to optimize \n","def negLL_Norm(params, raw_data):\n","    mu, sigma = params[0], params[1]\n","\n","    # Log likelihood function of the entire data (sum of the log(f(x_i|parameters)) of each data point x_i)\n","    LL = np.sum(stats.norm.logpdf(raw_data, loc=mu, scale=sigma))\n","\n","    # minimize the negative log likelihood\n","    negLL = -LL\n","\n","    return(negLL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2ZWkJO1tgYO"},"source":["print(negLL_Norm(params=(2, 3), raw_data = raw_data1)) # mu = 2, sigma = 3, what is the -LL of the entire data?\n","print(negLL_Norm(params=(1, 1), raw_data = raw_data1)) # mu = 1, sigma = 1, what is the -LL of the entire data?"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"95RUMKP8TvFW"},"source":["result = minimize(partial(negLL_Norm, raw_data=raw_data1), x0=(2, 3), method = 'Nelder-Mead', options={'disp': True})\n","\n","print(\"\\n\", \n","      \"The parameters we get from MLE: \", \"\\n\", \n","      \"MLE estimate mean (mu-hat): \", result['x'][0], \"\\n\",\n","      \"MLE estimate std (sigma-hat): \", result['x'][1], \"\\n\",\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLP4pLRXXUfx"},"source":["## Example 2"]},{"cell_type":"code","metadata":{"id":"2ptywltrKzu1"},"source":["raw_data2 = np.loadtxt('https://fmai-teaching.s3.amazonaws.com/bia652/est/g.txt')\n","histogram = plt.hist(raw_data2, bins=20)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1cHxxb-YwEL"},"source":["\n","# let's assume that the data is generated from a gamma distribution\n","def negLL_Gama(params, raw_data):\n","    \n","    alpha, beta = params[0], params[1]\n","    LL = np.sum(stats.gamma.logpdf(raw_data, alpha, scale=(1/beta))) # scale = 1/beta, pay attention to the parameterization of gamma distribution \n","    negLL = -LL\n","    \n","    return(negLL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwOkBhR2YwG6"},"source":["result = minimize(partial(negLL_Gama, raw_data=raw_data2), x0 = (0, 1), method = 'Nelder-Mead', options={'disp': True})\n","\n","print(\"\\n\", \n","      \"The parameters we get from MLE: \", \"\\n\", \n","      \"MLE estimate alpha-hat: \", result['x'][0], \"\\n\",\n","      \"MLE estimate beta-hat: \", result['x'][1], \"\\n\"\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOw4cZa1Kzu2"},"source":["Sometimes we may mis-specify the model, for example, we mistakenly assumed that raw_data2 is generated by a Normal distribution. "]},{"cell_type":"code","metadata":{"id":"AckYZzysKzu3"},"source":["result = minimize(partial(negLL_Norm, raw_data=raw_data2), x0 = (0, 1), method = 'Nelder-Mead', options={'disp': True})\n","\n","print(\"\\n\", \n","      \"The parameters we get from MLE: \", \"\\n\", \n","      \"MLE estimate mu-hat: \", result['x'][0], \"\\n\",\n","      \"MLE estimate sigma-hat: \", result['x'][1], \"\\n\"\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOE2CfDcKzu3"},"source":["What if we mistakenly assumed that raw_data2 is generated by an exponential distribution? Note that it has a single parameter (mu or scale).  "]},{"cell_type":"code","metadata":{"id":"BvrCZz0IKzu3"},"source":["def negLL_Exp(mu, raw_data):\n","    LL = np.sum(stats.expon.logpdf(raw_data, scale=mu))\n","    negLL = -LL\n","\n","    return(negLL)\n","\n","result = minimize(partial(negLL_Exp, raw_data=raw_data2), x0 = ((0.5)),  options={'disp': True})\n","\n","print(\"\\n\", \n","      \"The parameters we get from MLE: \", \"\\n\", \n","      \"MLE estimate mu-hat: \", result['x'][0], \"\\n\",\n","      )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KY1WXT2ADrO7"},"source":["# Method of Moments (MoM)"]},{"cell_type":"markdown","metadata":{"id":"gjNbQ3Yxdf-f"},"source":["## Normal distribution"]},{"cell_type":"code","metadata":{"id":"rCiM3LlDDt21"},"source":["# MoM matches sample moments with the RV moments to estimate the parameters\n","# for example, for normal distribution, we need to estimate the mean and std\n","# so we only need the first two moment\n","\n","print(\"MoM estimates \\n\",\n","      \"mean (mu-hat): \", np.mean(raw_data1), \"\\n\",\n","      \"std dev (sigma-hat): \", np.std(raw_data1), \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x8pV_LKOeHi1"},"source":["## Gamma distribution"]},{"cell_type":"code","metadata":{"id":"MgGMXi1DDt7y"},"source":["# the mean (first moment) of gamma distribution is: alpha/beta\n","# the variance (2nd central moment) of gamma distribution is: alpha/beta^2\n","\n","# we only have two unknown variables\n","# so we solve the following systems of equations using fsolve using the first two moments:\n","# alpha/beta = np.mean(raw_data) --> alpha/beta - np.mean(raw_data) = 0\n","# alpha/(beta**2) = np.var(raw_data) --> alpha/(beta**2) - np.var(raw_data) = 0\n","\n","\n","# let's use python to build a formula solver\n","def fun_1(z):\n","\n","    alpha = z[0]\n","    beta = z[1]\n","\n","    F = np.empty((2))\n","    F[0] = alpha / beta - np.mean(raw_data2)\n","    F[1] = alpha / (beta ** 2) - np.var(raw_data2)\n","\n","    return F\n","\n","\n","results = fsolve(fun_1, x0=np.array([1, 1])) # 1,1 are the initial guesses\n","\n","print(\n","    \"MoM estimates \\n\", \"alpha-hat: \", results[0], \"\\n\", \"beta-hat: \", results[1], \"\\n\"\n",")\n","\n"],"execution_count":null,"outputs":[]}]}